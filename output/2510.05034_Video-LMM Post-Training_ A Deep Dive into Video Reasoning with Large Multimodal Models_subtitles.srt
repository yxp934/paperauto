1
00:00:00,000 --> 00:00:05,000
AI Research Explained

2
00:00:00,000 --> 00:00:26,199
视频AI的下一个突破口，不在于更大的模型，而在于更聪明的“后训练”方法。面对碎片化的研究现状，这篇开创性综述首次提出了SFT、RL、TTS三大支柱，为Video-LMM如何真正理解视频构建了第一个清晰框架。

3
00:00:26,199 --> 00:00:41,302
Hello everyone, and welcome. We interact with video content almost daily, and a

4
00:00:40,802 --> 00:00:55,904
long-standing goal in AI has been to enable machines to understand the complex

5
00:00:55,405 --> 00:01:10,507
dynamics within these videos, just like humans do. Recently, Video Large

6
00:01:10,007 --> 00:01:24,609
Multimodal Models, or Video-LMMs, have made significant strides in understanding

7
00:01:24,609 --> 00:01:44,232
Before we dive into our main topic, let's set the stage with some background.

8
00:01:43,732 --> 00:02:03,355
Large Multimodal Models, or LMMs, like the well-known GPT-4V, can already

9
00:02:02,854 --> 00:02:22,477
understand both images and text. When we extend this capability to the video

10
00:02:21,977 --> 00:02:41,099
domain, we get Video-LMMs. However, video is far more complex than a static

11
00:05:10,439 --> 00:05:37,884
Since this paper is a survey, our contribution isn't a new model that sets a

12
00:05:37,384 --> 00:06:04,829
state-of-the-art record. Instead, through a systematic review, we demonstrate

13
00:06:04,329 --> 00:06:31,774
the immense value of post-training methods across a wide range of applications.

14
00:06:31,274 --> 00:06:58,220
For complex spatio-temporal reasoning, like analyzing tactical plays in a sports

15
00:06:58,220 --> 00:07:22,525
This paper represents a landmark contribution to the field. For the first time,

16
00:07:22,025 --> 00:07:46,330
it provides a clear and systematic framework for the somewhat fragmented

17
00:07:45,830 --> 00:08:10,135
research area of Video-LMM post-training. Our 'three-pillar' classification not

18
00:08:09,634 --> 00:08:33,440
only helps researchers understand the connections between existing works but

19
00:08:33,440 --> 00:08:54,420
In conclusion, this paper offers a comprehensive guide to the advanced evolution

20
00:08:53,920 --> 00:09:14,900
of Video-LMMs. It systematically organizes the core methodologies for enhancing

21
00:09:14,400 --> 00:09:35,380
video reasoning capabilities through a taxonomy built on three pillars:

22
00:09:34,880 --> 00:09:55,360
Supervised Fine-Tuning with Chain-of-Thought, Reinforcement Learning-based

23
00:09:55,360 --> 00:09:58,360
Thanks for watching!
