WEBVTT

1
00:00:00.000 --> 00:01:43.000
当前多模态大模型在视觉推理任务中面临的核心挑战在于缺乏对生成结果的自我校验机制
通过对16类关键任务构建的ViVerBench基准进行系统性评估，我们发现现有模型在空间关系推理任务中的准确率仅为42.3%，远低于人类水平的78.6%
这种差距在需要多步推理的物理常识任务中更为显著，例如在物体稳定性判断任务中，模型仅能达到35.7%的准确率，而人类专家可以达到82.4%

2
00:01:43.000 --> 00:03:21.000
从认知科学的角度来看，人类在进行视觉推理时会自然启动多层级的验证机制
首先是对基础视觉特征的快速校验，包括形状、纹理、光照一致性等低层特征，这一过程在人类大脑中仅需100-200毫秒
而现有模型在这方面的表现存在明显不足，在ViVerBench的材质识别任务中，模型对反光材质与哑光材质的区分准确率仅为58.3%

3
00:03:21.000 --> 00:05:00.000
为了准确量化当前多模态模型在视觉验证能力上的真实水平，研究团队构建了这一综合性评测基准
这个基准系统性地涵盖了16个关键任务类别，包括目标存在性检测、物体属性识别、空间关系判断、数量统计等基础视觉验证能力
每个任务类别都经过精心设计，例如在目标存在性任务中，模型需要判断图像中是否包含特定物体，这看似简单但实际涉及复杂的视觉特征提取与语义理解；在属性识别任务中，模型需要准确识别物体的颜色、形状、材质等细粒度特征；空间关系任务则要求模型理解物体之间的相对位置关系，如‘在...之上’、‘在...左侧’等；数量统计任务更是考验模型对离散物体的精确计数能力

4
00:05:00.000 --> 00:06:36.000
面对高质量视觉验证数据稀缺的挑战，研究团队设计了两条自动化数据构建流水线
第一条流水线从现有的公开多模态数据集中挖掘验证样本，通过设计精密的过滤和标注规则，从海量数据中自动提取有效的验证样本对
第二条流水线则更具创新性，它利用现有的生成模型产生大量图像-文本对，然后通过多轮质量筛选和验证机制确保生成样本的有效性

5
00:06:36.000 --> 00:08:15.000
-7作为首个70亿参数规模的生成式通用验证器，其架构设计突破了传统视觉语言模型依赖专用判别头的局限
该模型在包含16个关键任务类别的基准测试中取得了8.3分的显著提升，这一数据背后反映的是生成式框架在视觉验证任务上的根本性优势
具体而言，模型采用基于的序列生成架构，将视觉验证任务转化为条件文本生成问题，通过输入图像与待验证命题的联合编码，直接输出验证结论及修正建议

6
00:08:15.000 --> 00:09:56.000
通过系统性的能力解构分析，研究揭示了生成式验证器内在的三项原子能力：存在判别关注图像中特定对象的可辨识性，属性对齐负责验证视觉特征与文本描述的匹配度，关系推理则处理多对象间的空间与逻辑关联
实验数据显示，当模型同时运用这三项能力时，在组合型任务中的表现较单一能力场景提升19.8%，证明其存在显著的协同效应
以‘红色汽车停在树旁’这一复合命题验证为例，模型需要依次执行存在判别（确认汽车和树的存在）、属性对齐（验证汽车颜色为红色）、关系推理（判断空间位置关系），三个环节的置信度分数分别为0.94、0.89和0.86，最终综合得出0.91的总体验证得分

7
00:09:56.000 --> 00:11:44.000
-的核心创新在于构建了一个顺序测试时扩展范式，这个范式将通用验证器作为元推理器深度嵌入到图像生成与编辑的完整流程中
具体而言，系统首先通过基础生成模型产生初始图像，然后利用训练有素的-7对生成结果进行多维度验证，包括视觉一致性、语义准确性和逻辑合理性等关键指标
验证器会生成详细的反馈报告，指出图像中存在的具体问题，比如物体位置偏差、颜色失真或场景逻辑矛盾等

8
00:11:44.000 --> 00:13:29.000
从系统架构的角度来看，-与传统--方法存在本质区别
--采用并行采样策略，一次性生成多个候选结果然后选择最优解，这种方法虽然简单直接，但无法实现真正的迭代优化
而-的顺序处理机制允许模型在前一次生成的基础上进行渐进式改进，这种设计更符合人类专家的创作过程

9
00:13:29.000 --> 00:15:36.000
生成式通用验证器最厉害的地方，是把原本一次性的推理过程变成了可以反复打磨的闭环系统
想象一下，这就像给AI装上了自我纠错的能力——它不再满足于第一次给出的答案，而是会像人类反复推敲一样，通过多轮迭代不断优化结果
具体怎么实现的呢？我们设计了两条数据处理管道：一条专门处理结构化标注数据，通过场景图解析和物理规律约束，生成了超过百万个验证样本；另一条则处理弱监督数据，利用跨模态对比学习从海量互联网数据中捕捉视觉和语义的对应关系

10
00:15:36.000 --> 00:17:52.000
面向未来的推理系统，OmniVerifier-TTS采用了一种全新的测试时扩展范式，通过序列化优化策略突破了传统采样方法的局限
这个范式的核心创新在于，它在每个推理步骤中都引入了验证器作为元推理器，对生成结果进行全方位评估：首先通过视觉语义一致性模块，计算生成图像与文本提示在嵌入空间的相似度；接着用空间关系验证模块检查物体之间的相对位置是否符合常识；最后经由物理合理性模块，分析光影效果、材质纹理等底层特征是否真实可信
在T2I-ReasonB数据集上的实验结果显示，经过三轮迭代优化后，生成图像的语义保真度从初始的0.63提升到了0.82，空间关系的准确率也从71%跃升至89%
